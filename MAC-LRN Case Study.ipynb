{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAC-LRN Case Study\n",
    "   ## Members:\n",
    "   ### Caguiat, EJ\n",
    "   ### Caro, Patricia\n",
    "   ### Dienzo, Jericho Rafael\n",
    " \n",
    "## Dataset: \"Titanic: Machine Learning from Disaster\"\n",
    "\n",
    " \n",
    " \n",
    " \n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction of the problem and dataset\n",
    "### The training dataset that we are currently using describes different features for each passenger aboard the Titanic and shows whether or not they survived. The task is to correctly classify whether or not a given person with a given set of features (from the test dataset) would survive based on the training dataset.\n",
    "#### The link to the kaggle dataset that we used: https://www.kaggle.com/c/titanic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# List of requirements\n",
    "### The list of requirements that we used, and what we think are necessary in order to tackle this problem, are:\n",
    "#### - Pandas (A Python library built on NumPy which is commonly used for machine learning problems)\n",
    "#### - NumPy (A Python library used to process numerical data)\n",
    "#### - The Kaggle Dataset (specifically the Titanic dataset) which can be obtained from the link provided above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import of necessary libraries and data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "csvfile = pd.read_csv(\"/Users/Jericho/Documents/Subjects/MAC-LRN/all/train.csv\")\n",
    "print(csvfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data analysis\n",
    "### The dataset that we used had many different features per person, all of which we deemed necessary in determining whether or not the person would live (more on this later). There were many anomalies in the dataset, such as null fields, fields that contained different datatypes than intended (int fields having chars), etc. Thus the data cleaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
