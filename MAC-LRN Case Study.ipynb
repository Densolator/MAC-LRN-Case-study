{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAC-LRN Case Study\n",
    "   ## Members:\n",
    "   ### Caguiat, EJ\n",
    "   ### Caro, Patricia\n",
    "   ### Dienzo, Jericho Rafael\n",
    " \n",
    "## Dataset: \"Titanic: Machine Learning from Disaster\"\n",
    "\n",
    " \n",
    " \n",
    " \n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction of the problem and dataset\n",
    "### The training dataset that we are currently using describes different features for each passenger aboard the Titanic and shows whether or not they survived. The task is to correctly classify whether or not a given person with a given set of features (from the test dataset) would survive based on the training dataset.\n",
    "#### The link to the kaggle dataset that we used: https://www.kaggle.com/c/titanic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# List of requirements\n",
    "### The list of requirements that we used, and what we think are necessary in order to tackle this problem, are:\n",
    "#### - Pandas (A Python library built on NumPy which is commonly used for machine learning problems)\n",
    "#### - NumPy (A Python library used to process numerical data)\n",
    "#### - The Kaggle Dataset (specifically the Titanic dataset) which can be obtained from the link provided above\n",
    "#### - Matplotlib (A Python library used for plotting)\n",
    "#### - Seaborn (A Python for data visualization)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import of necessary libraries and data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import random as rnd\n",
    "trainfile = pd.read_csv(\"train.csv\")\n",
    "testfile = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data analysis\n",
    "### The dataset that we used had many different features per person, all of which we deemed necessary in determining whether or not the person would live, except for the Passenger ID, ticket field and cabin(more on this later). There were many anomalies in the dataset, such as null fields, fields that contained different datatypes than intended (int fields having chars), etc. Thus the data cleaning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The data in the training dataset\n",
    "#### We can see in the given dataset that the Passenger ID is simply a unique identifier and would not be needed in determining whether or not a person survives\n",
    "#### The Ticket is also given, although it is very hard to attribute it to any part of a person's survivability. The number given is also vague, thus a correlation between the Train column and the other columns could not be established."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     PassengerId  Survived  Pclass  \\\n",
      "0              1         0       3   \n",
      "1              2         1       1   \n",
      "2              3         1       3   \n",
      "3              4         1       1   \n",
      "4              5         0       3   \n",
      "5              6         0       3   \n",
      "6              7         0       1   \n",
      "7              8         0       3   \n",
      "8              9         1       3   \n",
      "9             10         1       2   \n",
      "10            11         1       3   \n",
      "11            12         1       1   \n",
      "12            13         0       3   \n",
      "13            14         0       3   \n",
      "14            15         0       3   \n",
      "15            16         1       2   \n",
      "16            17         0       3   \n",
      "17            18         1       2   \n",
      "18            19         0       3   \n",
      "19            20         1       3   \n",
      "20            21         0       2   \n",
      "21            22         1       2   \n",
      "22            23         1       3   \n",
      "23            24         1       1   \n",
      "24            25         0       3   \n",
      "25            26         1       3   \n",
      "26            27         0       3   \n",
      "27            28         0       1   \n",
      "28            29         1       3   \n",
      "29            30         0       3   \n",
      "..           ...       ...     ...   \n",
      "861          862         0       2   \n",
      "862          863         1       1   \n",
      "863          864         0       3   \n",
      "864          865         0       2   \n",
      "865          866         1       2   \n",
      "866          867         1       2   \n",
      "867          868         0       1   \n",
      "868          869         0       3   \n",
      "869          870         1       3   \n",
      "870          871         0       3   \n",
      "871          872         1       1   \n",
      "872          873         0       1   \n",
      "873          874         0       3   \n",
      "874          875         1       2   \n",
      "875          876         1       3   \n",
      "876          877         0       3   \n",
      "877          878         0       3   \n",
      "878          879         0       3   \n",
      "879          880         1       1   \n",
      "880          881         1       2   \n",
      "881          882         0       3   \n",
      "882          883         0       3   \n",
      "883          884         0       2   \n",
      "884          885         0       3   \n",
      "885          886         0       3   \n",
      "886          887         0       2   \n",
      "887          888         1       1   \n",
      "888          889         0       3   \n",
      "889          890         1       1   \n",
      "890          891         0       3   \n",
      "\n",
      "                                                  Name     Sex   Age  SibSp  \\\n",
      "0                              Braund, Mr. Owen Harris    male  22.0      1   \n",
      "1    Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
      "2                               Heikkinen, Miss. Laina  female  26.0      0   \n",
      "3         Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
      "4                             Allen, Mr. William Henry    male  35.0      0   \n",
      "5                                     Moran, Mr. James    male   NaN      0   \n",
      "6                              McCarthy, Mr. Timothy J    male  54.0      0   \n",
      "7                       Palsson, Master. Gosta Leonard    male   2.0      3   \n",
      "8    Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)  female  27.0      0   \n",
      "9                  Nasser, Mrs. Nicholas (Adele Achem)  female  14.0      1   \n",
      "10                     Sandstrom, Miss. Marguerite Rut  female   4.0      1   \n",
      "11                            Bonnell, Miss. Elizabeth  female  58.0      0   \n",
      "12                      Saundercock, Mr. William Henry    male  20.0      0   \n",
      "13                         Andersson, Mr. Anders Johan    male  39.0      1   \n",
      "14                Vestrom, Miss. Hulda Amanda Adolfina  female  14.0      0   \n",
      "15                    Hewlett, Mrs. (Mary D Kingcome)   female  55.0      0   \n",
      "16                                Rice, Master. Eugene    male   2.0      4   \n",
      "17                        Williams, Mr. Charles Eugene    male   NaN      0   \n",
      "18   Vander Planke, Mrs. Julius (Emelia Maria Vande...  female  31.0      1   \n",
      "19                             Masselmani, Mrs. Fatima  female   NaN      0   \n",
      "20                                Fynney, Mr. Joseph J    male  35.0      0   \n",
      "21                               Beesley, Mr. Lawrence    male  34.0      0   \n",
      "22                         McGowan, Miss. Anna \"Annie\"  female  15.0      0   \n",
      "23                        Sloper, Mr. William Thompson    male  28.0      0   \n",
      "24                       Palsson, Miss. Torborg Danira  female   8.0      3   \n",
      "25   Asplund, Mrs. Carl Oscar (Selma Augusta Emilia...  female  38.0      1   \n",
      "26                             Emir, Mr. Farred Chehab    male   NaN      0   \n",
      "27                      Fortune, Mr. Charles Alexander    male  19.0      3   \n",
      "28                       O'Dwyer, Miss. Ellen \"Nellie\"  female   NaN      0   \n",
      "29                                 Todoroff, Mr. Lalio    male   NaN      0   \n",
      "..                                                 ...     ...   ...    ...   \n",
      "861                        Giles, Mr. Frederick Edward    male  21.0      1   \n",
      "862  Swift, Mrs. Frederick Joel (Margaret Welles Ba...  female  48.0      0   \n",
      "863                  Sage, Miss. Dorothy Edith \"Dolly\"  female   NaN      8   \n",
      "864                             Gill, Mr. John William    male  24.0      0   \n",
      "865                           Bystrom, Mrs. (Karolina)  female  42.0      0   \n",
      "866                       Duran y More, Miss. Asuncion  female  27.0      1   \n",
      "867               Roebling, Mr. Washington Augustus II    male  31.0      0   \n",
      "868                        van Melkebeke, Mr. Philemon    male   NaN      0   \n",
      "869                    Johnson, Master. Harold Theodor    male   4.0      1   \n",
      "870                                  Balkic, Mr. Cerin    male  26.0      0   \n",
      "871   Beckwith, Mrs. Richard Leonard (Sallie Monypeny)  female  47.0      1   \n",
      "872                           Carlsson, Mr. Frans Olof    male  33.0      0   \n",
      "873                        Vander Cruyssen, Mr. Victor    male  47.0      0   \n",
      "874              Abelson, Mrs. Samuel (Hannah Wizosky)  female  28.0      1   \n",
      "875                   Najib, Miss. Adele Kiamie \"Jane\"  female  15.0      0   \n",
      "876                      Gustafsson, Mr. Alfred Ossian    male  20.0      0   \n",
      "877                               Petroff, Mr. Nedelio    male  19.0      0   \n",
      "878                                 Laleff, Mr. Kristo    male   NaN      0   \n",
      "879      Potter, Mrs. Thomas Jr (Lily Alexenia Wilson)  female  56.0      0   \n",
      "880       Shelley, Mrs. William (Imanita Parrish Hall)  female  25.0      0   \n",
      "881                                 Markun, Mr. Johann    male  33.0      0   \n",
      "882                       Dahlberg, Miss. Gerda Ulrika  female  22.0      0   \n",
      "883                      Banfield, Mr. Frederick James    male  28.0      0   \n",
      "884                             Sutehall, Mr. Henry Jr    male  25.0      0   \n",
      "885               Rice, Mrs. William (Margaret Norton)  female  39.0      0   \n",
      "886                              Montvila, Rev. Juozas    male  27.0      0   \n",
      "887                       Graham, Miss. Margaret Edith  female  19.0      0   \n",
      "888           Johnston, Miss. Catherine Helen \"Carrie\"  female   NaN      1   \n",
      "889                              Behr, Mr. Karl Howell    male  26.0      0   \n",
      "890                                Dooley, Mr. Patrick    male  32.0      0   \n",
      "\n",
      "     Parch            Ticket      Fare        Cabin Embarked  \n",
      "0        0         A/5 21171    7.2500          NaN        S  \n",
      "1        0          PC 17599   71.2833          C85        C  \n",
      "2        0  STON/O2. 3101282    7.9250          NaN        S  \n",
      "3        0            113803   53.1000         C123        S  \n",
      "4        0            373450    8.0500          NaN        S  \n",
      "5        0            330877    8.4583          NaN        Q  \n",
      "6        0             17463   51.8625          E46        S  \n",
      "7        1            349909   21.0750          NaN        S  \n",
      "8        2            347742   11.1333          NaN        S  \n",
      "9        0            237736   30.0708          NaN        C  \n",
      "10       1           PP 9549   16.7000           G6        S  \n",
      "11       0            113783   26.5500         C103        S  \n",
      "12       0         A/5. 2151    8.0500          NaN        S  \n",
      "13       5            347082   31.2750          NaN        S  \n",
      "14       0            350406    7.8542          NaN        S  \n",
      "15       0            248706   16.0000          NaN        S  \n",
      "16       1            382652   29.1250          NaN        Q  \n",
      "17       0            244373   13.0000          NaN        S  \n",
      "18       0            345763   18.0000          NaN        S  \n",
      "19       0              2649    7.2250          NaN        C  \n",
      "20       0            239865   26.0000          NaN        S  \n",
      "21       0            248698   13.0000          D56        S  \n",
      "22       0            330923    8.0292          NaN        Q  \n",
      "23       0            113788   35.5000           A6        S  \n",
      "24       1            349909   21.0750          NaN        S  \n",
      "25       5            347077   31.3875          NaN        S  \n",
      "26       0              2631    7.2250          NaN        C  \n",
      "27       2             19950  263.0000  C23 C25 C27        S  \n",
      "28       0            330959    7.8792          NaN        Q  \n",
      "29       0            349216    7.8958          NaN        S  \n",
      "..     ...               ...       ...          ...      ...  \n",
      "861      0             28134   11.5000          NaN        S  \n",
      "862      0             17466   25.9292          D17        S  \n",
      "863      2          CA. 2343   69.5500          NaN        S  \n",
      "864      0            233866   13.0000          NaN        S  \n",
      "865      0            236852   13.0000          NaN        S  \n",
      "866      0     SC/PARIS 2149   13.8583          NaN        C  \n",
      "867      0          PC 17590   50.4958          A24        S  \n",
      "868      0            345777    9.5000          NaN        S  \n",
      "869      1            347742   11.1333          NaN        S  \n",
      "870      0            349248    7.8958          NaN        S  \n",
      "871      1             11751   52.5542          D35        S  \n",
      "872      0               695    5.0000  B51 B53 B55        S  \n",
      "873      0            345765    9.0000          NaN        S  \n",
      "874      0         P/PP 3381   24.0000          NaN        C  \n",
      "875      0              2667    7.2250          NaN        C  \n",
      "876      0              7534    9.8458          NaN        S  \n",
      "877      0            349212    7.8958          NaN        S  \n",
      "878      0            349217    7.8958          NaN        S  \n",
      "879      1             11767   83.1583          C50        C  \n",
      "880      1            230433   26.0000          NaN        S  \n",
      "881      0            349257    7.8958          NaN        S  \n",
      "882      0              7552   10.5167          NaN        S  \n",
      "883      0  C.A./SOTON 34068   10.5000          NaN        S  \n",
      "884      0   SOTON/OQ 392076    7.0500          NaN        S  \n",
      "885      5            382652   29.1250          NaN        Q  \n",
      "886      0            211536   13.0000          NaN        S  \n",
      "887      0            112053   30.0000          B42        S  \n",
      "888      2        W./C. 6607   23.4500          NaN        S  \n",
      "889      0            111369   30.0000         C148        C  \n",
      "890      0            370376    7.7500          NaN        Q  \n",
      "\n",
      "[891 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "print(trainfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Graph showing the amount of people that did or did not survive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x='Survived', data=trainfile);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning\n",
    "### The removal of PassengerId was done because it had no bearing on whether or not the person would survive. \n",
    "### The removal of the Ticket field was also done for the same reasons as the PassengerId. It is also hard to identify exactly what the Ticket field is specifying (if anything at all).\n",
    "### The cabin field might appear as important in determining whether or not a person lives as the other features/factors (after all, the people residing in nearest cabins to the top of the ship have a better chance of surviving), but upon closer inspection, one would come to realize that the Ticket field is nothing but an unnecessary field presenting redundant information. It presents the same data as the Fare and PClass, in that you can already derive a person's status from the Fare and PClass. We can then infer exactly what the person's social status is and, as a result, be able to infer where they are staying on the ship. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnsdropped = ['PassengerId', 'Ticket', 'Cabin']\n",
    "ports = ['S', 'C', 'Q']\n",
    "trainfile.drop(columnsdropped, inplace = True, axis = 1)\n",
    "testfile.drop(columnsdropped, inplace = True, axis = 1)\n",
    "\n",
    "for x in range(0, trainfile['Age'].size - 1):\n",
    "    if pd.isnull(trainfile.Age.iloc[x]):\n",
    "        trainfile.at[x, 'Age'] = np.random.uniform(low = trainfile.Age.min(), high = trainfile.Age.max())\n",
    "\n",
    "for x in range(0, testfile['Age'].size - 1):\n",
    "    if pd.isnull(testfile.Age.iloc[x]):\n",
    "        testfile.at[x, 'Age'] = np.random.uniform(low = testfile.Age.min(), high = testfile.Age.max())\n",
    "        \n",
    "for x in range(0, trainfile['Embarked'].size - 1):\n",
    "    if pd.isnull(trainfile.Embarked.iloc[x]):\n",
    "        trainfile.at[x, 'Embarked'] = rnd.choice(ports)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reference https://www.kaggle.com/gaurav9297/titanic-using-knn\n",
    "\n",
    "#feature selection (select relevant columns from data)\n",
    "label=trainfile.iloc[0:890,0]\n",
    "data=trainfile.iloc[0:890,[1,3,4,5,6,7,8]]\n",
    "testdat=testfile.iloc[0:418,[0,2,3,4,5,6,7]]\n",
    "x=[data,testdat]\n",
    "\n",
    "#normalization of 'sex' column\n",
    "for change in x:\n",
    "    change['Sex']=change['Sex'].map({'female':0,'male':1}).astype(int)\n",
    "    \n",
    "#normalization of 'Embarked' column\n",
    "for change in x:\n",
    "    change['Embarked'] = change['Embarked'].map({'S':0, 'C':1, 'Q':2}).astype(int)\n",
    "\n",
    "#part of preprocessing\n",
    "data=(data.fillna(0)) #filling NA values\n",
    "testdat=testdat.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combining and splitting data to remove 'bias'\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_data,test_data,train_labels,test_labels=train_test_split(data,label,random_state=7,train_size=0.7, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithms used"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FIRST ALGORITHM: KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73.41\n"
     ]
    }
   ],
   "source": [
    "#start KNN\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn=KNeighborsClassifier(n_neighbors=10)\n",
    "knn.fit(data,label)\n",
    "predictions=knn.predict(test_data)\n",
    "#print(predictions)\n",
    "    \n",
    "#accuracy percentage\n",
    "knn_accuracy = round(accuracy_score(test_labels,predictions)*100,2)\n",
    "\n",
    "    \n",
    "print(knn_accuracy)\n",
    "    #what you can do here is LOOP yung whole KNN code (peds mo naman ilagay into one cell lahat) \n",
    "    #so you loop and increment mo yung 'n_neighbors' paremeter ng KNeighborsClassifier\n",
    "    #then you store the different accuracies per iteration in an array to check how many neighbors is best to use\n",
    "    #tas i-graph mo using matplotlib\n",
    "    #add it nalang sa next cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SECOND ALGORITHM: PERCEPTRON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ej caguiat\\appdata\\local\\programs\\python\\python36-32\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#import necessary libraries\n",
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "perceptron = Perceptron(eta0=0.9) #changing LR\n",
    "perceptron.fit(data,label)\n",
    "Y_pred = perceptron.predict(test_data)\n",
    "acc_perceptron = round(perceptron.score(data,label) * 100, 2)\n",
    "    \n",
    "\n",
    "print(acc_perceptron)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### THIRD ALGORITHM: SUPPORT VECTOR MACHINES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89.44\n"
     ]
    }
   ],
   "source": [
    "#import files\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "svc = SVC()\n",
    "svc.fit(data,label)\n",
    "Y_pred = svc.predict(test_data)\n",
    "acc_svc = round(svc.score(data,label) * 100, 2)\n",
    "    \n",
    "print(acc_svc)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
